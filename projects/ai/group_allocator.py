"""
Off-chain AI group allocator.
Provides allocate_groups() which builds groups maximizing skill diversity,
hashes group records, writes local records and attempts to store on-chain
via generated GroupAllocator client if available.
"""
from dataclasses import dataclass
from typing import List, Dict, Tuple
import hashlib
import json
import logging

import algokit_utils

logger = logging.getLogger(__name__)


@dataclass
class Student:
    wallet_address: str
    skills: List[str]
    preferences: List[str]


def _sha256_hex(value: str) -> str:
    return hashlib.sha256(value.encode("utf-8")).hexdigest()


def allocate_groups(students: List[Student], group_size: int = 4) -> List[Dict]:
    """Simple heuristic allocator:
    - tries to maximize skill diversity by distributing students by dominant skill
    - respects preferences when possible by trying to put preferred roles into different groups
    - returns list of groups: {group_id:int, members:[addresses], metadata_hash:str}

    This function also persists results to projects/ai/group_records.json and
    will attempt an on-chain store if a GroupAllocator client is available in
    smart_contracts.artifacts.group_allocator (generated by algokit tooling).
    """
    if not students:
        return []

    # Determine dominant skill (first skill) for each student if available
    buckets: Dict[str, List[Student]] = {}
    for s in students:
        dominant = s.skills[0] if s.skills else "none"
        buckets.setdefault(dominant, []).append(s)

    # Prepare empty groups
    num_groups = (len(students) + group_size - 1) // group_size
    groups: List[List[Student]] = [[] for _ in range(num_groups)]

    # Round-robin assign students grouped by dominant skill to maximize diversity
    group_idx = 0
    for skill, bucket in sorted(buckets.items(), key=lambda kv: -len(kv[1])):
        for student in bucket:
            groups[group_idx].append(student)
            group_idx = (group_idx + 1) % num_groups

    # Post-process to ensure group sizes not exceeded (flatten overflow)
    flat = [s for grp in groups for s in grp]
    groups = [flat[i : i + group_size] for i in range(0, len(flat), group_size)]

    # Respect simple preferences: attempt to distribute students with identical single preference
    # (best-effort, lightweight heuristic)
    # (Already handled by bucket distribution above.)

    result = []
    for i, grp in enumerate(groups):
        wallets = [s.wallet_address for s in grp]
        joined = ",".join(sorted(wallets))
        metadata = {
            "group_id": i + 1,
            "members": wallets,
        }
        meta_json = json.dumps(metadata, sort_keys=True)
        meta_hash = _sha256_hex(meta_json)

        record = {"group_id": i + 1, "members": wallets, "metadata_hash": meta_hash}
        result.append(record)

    # persist locally for demo and debugging
    try:
        with open("projects/ai/group_records.json", "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2)
    except Exception as e:
        logger.warning("Failed to write local group_records.json: %s", e)

    # Attempt on-chain store if possible (best-effort).
    try:
        # Try to import generated client factory
        from smart_contracts.artifacts.group_allocator.group_allocator_client import (
            GroupAllocatorFactory,
        )

        algorand = algokit_utils.AlgorandClient.from_environment()
        deployer_ = algorand.account.from_environment("DEPLOYER")
        factory = algorand.client.get_typed_app_factory(
            GroupAllocatorFactory, default_sender=deployer_.address
        )

        # Try to resolve an app client by creator & name (idempotent if deployed)
        app_client = None
        try:
            app_client = factory.getAppClientByCreatorAndName({"creator": deployer_.address})
        except Exception:
            # Fallback: if factory has network-app ids built into spec
            try:
                app_client = factory.getAppClientById({"appId": factory.appFactory.appId})
            except Exception:
                app_client = None

        if app_client:
            # Wrap into client class
            client = GroupAllocatorFactory({"algorand": algorand.client}).getAppClientById
            # Use the generated client send interface if available. This is best-effort
            for rec in result:
                gid = rec["group_id"]
                members_bytes = ",".join(rec["members"]).encode("utf-8")
                hash_bytes = rec["metadata_hash"].encode("utf-8")
                try:
                    # Prefer typed send if available
                    if hasattr(app_client, "send") and hasattr(app_client.send, "create_group"):
                        # some generated clients expose: app_client.send.create_group(...)
                        awaitable = app_client.send.create_group({"args": [gid, members_bytes, hash_bytes]})
                        # If it's a coroutine-like, trigger send
                        if hasattr(awaitable, "__await__"):
                            import asyncio

                            asyncio.get_event_loop().run_until_complete(awaitable)
                    else:
                        logger.info("App client does not expose typed create_group.send; skipping on-chain write")
                except Exception as e:
                    logger.warning("Failed to write group %s on-chain: %s", gid, e)
    except Exception as e:
        logger.info("On-chain client not available or failed to run; continuing without on-chain writes: %s", e)

    return result


if __name__ == "__main__":
    # small demo runner
    students = [
        Student("ADDR1", ["python", "ml"], ["leader"]),
        Student("ADDR2", ["web", "js"], ["frontend"]),
        Student("ADDR3", ["ml", "python"], ["researcher"]),
        Student("ADDR4", ["web", "design"], ["ux"]),
        Student("ADDR5", ["ops"], ["infra"]),
    ]
    groups = allocate_groups(students, group_size=3)
    print(json.dumps(groups, indent=2))
